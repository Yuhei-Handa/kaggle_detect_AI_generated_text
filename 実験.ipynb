{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset as dt\n",
    "import pandas as pd\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import datasets\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_essays = pd.DataFrame(pd.read_csv(\"./dataset/train_essays.csv\"))\n",
    "train_prompts = pd.DataFrame(pd.read_csv(\"./dataset/train_prompts.csv\"))\n",
    "test_essays = pd.DataFrame(pd.read_csv(\"./dataset/test_essays.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1</td>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>ff669174</td>\n",
       "      <td>0</td>\n",
       "      <td>Limiting car usage has many advantages. Such a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>ffa247e0</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a new trend that has been developing f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>ffc237e9</td>\n",
       "      <td>0</td>\n",
       "      <td>As we all know cars are a big part of our soci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>ffe1ca0d</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars have been around since the 1800's and hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1378 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1     005db917          0  Transportation is a large necessity in most co...   \n",
       "2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3     00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...        ...        ...                                                ...   \n",
       "1373  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n",
       "1374  ff669174          0  Limiting car usage has many advantages. Such a...   \n",
       "1375  ffa247e0          0  There's a new trend that has been developing f...   \n",
       "1376  ffc237e9          0  As we all know cars are a big part of our soci...   \n",
       "1377  ffe1ca0d          0  Cars have been around since the 1800's and hav...   \n",
       "\n",
       "      generated  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "1373          0  \n",
       "1374          0  \n",
       "1375          0  \n",
       "1376          0  \n",
       "1377          0  \n",
       "\n",
       "[1378 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_id                       prompt_name  \\\n",
       "0          0                   Car-free cities   \n",
       "1          1  Does the electoral college work?   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  Write an explanatory essay to inform fellow ci...   \n",
       "1  Write a letter to your state senator in which ...   \n",
       "\n",
       "                                         source_text  \n",
       "0  # In German Suburb, Life Goes On Without Cars ...  \n",
       "1  # What Is the Electoral College? by the Office...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(train_essays, train_prompts, on='prompt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>fc66f374</td>\n",
       "      <td>1</td>\n",
       "      <td>The Electoral College was originally establish...</td>\n",
       "      <td>0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>fcb87d59</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear senator, I think that the presidential el...</td>\n",
       "      <td>0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>fcd93e2d</td>\n",
       "      <td>1</td>\n",
       "      <td>The electoral college is a group of electors t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>fcfe84cb</td>\n",
       "      <td>1</td>\n",
       "      <td>An electoral College compromises between elect...</td>\n",
       "      <td>0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1</td>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1378 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1     005db917          0  Transportation is a large necessity in most co...   \n",
       "2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3     00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...        ...        ...                                                ...   \n",
       "1373  fc66f374          1  The Electoral College was originally establish...   \n",
       "1374  fcb87d59          1  Dear senator, I think that the presidential el...   \n",
       "1375  fcd93e2d          1  The electoral college is a group of electors t...   \n",
       "1376  fcfe84cb          1  An electoral College compromises between elect...   \n",
       "1377  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n",
       "\n",
       "      generated                       prompt_name  \\\n",
       "0             0                   Car-free cities   \n",
       "1             0                   Car-free cities   \n",
       "2             0                   Car-free cities   \n",
       "3             0                   Car-free cities   \n",
       "4             0                   Car-free cities   \n",
       "...         ...                               ...   \n",
       "1373          0  Does the electoral college work?   \n",
       "1374          0  Does the electoral college work?   \n",
       "1375          0  Does the electoral college work?   \n",
       "1376          0  Does the electoral college work?   \n",
       "1377          0  Does the electoral college work?   \n",
       "\n",
       "                                           instructions  \\\n",
       "0     Write an explanatory essay to inform fellow ci...   \n",
       "1     Write an explanatory essay to inform fellow ci...   \n",
       "2     Write an explanatory essay to inform fellow ci...   \n",
       "3     Write an explanatory essay to inform fellow ci...   \n",
       "4     Write an explanatory essay to inform fellow ci...   \n",
       "...                                                 ...   \n",
       "1373  Write a letter to your state senator in which ...   \n",
       "1374  Write a letter to your state senator in which ...   \n",
       "1375  Write a letter to your state senator in which ...   \n",
       "1376  Write a letter to your state senator in which ...   \n",
       "1377  Write a letter to your state senator in which ...   \n",
       "\n",
       "                                            source_text  \n",
       "0     # In German Suburb, Life Goes On Without Cars ...  \n",
       "1     # In German Suburb, Life Goes On Without Cars ...  \n",
       "2     # In German Suburb, Life Goes On Without Cars ...  \n",
       "3     # In German Suburb, Life Goes On Without Cars ...  \n",
       "4     # In German Suburb, Life Goes On Without Cars ...  \n",
       "...                                                 ...  \n",
       "1373  # What Is the Electoral College? by the Office...  \n",
       "1374  # What Is the Electoral College? by the Office...  \n",
       "1375  # What Is the Electoral College? by the Office...  \n",
       "1376  # What Is the Electoral College? by the Office...  \n",
       "1377  # What Is the Electoral College? by the Office...  \n",
       "\n",
       "[1378 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df = merged_df.where(merged_df[\"generated\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>instructions</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Car-free cities</td>\n",
       "      <td>Write an explanatory essay to inform fellow ci...</td>\n",
       "      <td># In German Suburb, Life Goes On Without Cars ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>fc66f374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The Electoral College was originally establish...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>fcb87d59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dear senator, I think that the presidential el...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>fcd93e2d</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The electoral college is a group of electors t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>fcfe84cb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>An electoral College compromises between elect...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Does the electoral college work?</td>\n",
       "      <td>Write a letter to your state senator in which ...</td>\n",
       "      <td># What Is the Electoral College? by the Office...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1378 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "0     0059830c        0.0  Cars. Cars have been around since they became ...   \n",
       "1     005db917        0.0  Transportation is a large necessity in most co...   \n",
       "2     008f63e3        0.0  \"America's love affair with it's vehicles seem...   \n",
       "3     00940276        0.0  How often do you ride in a car? Do you drive a...   \n",
       "4     00c39458        0.0  Cars are a wonderful thing. They are perhaps o...   \n",
       "...        ...        ...                                                ...   \n",
       "1373  fc66f374        1.0  The Electoral College was originally establish...   \n",
       "1374  fcb87d59        1.0  Dear senator, I think that the presidential el...   \n",
       "1375  fcd93e2d        1.0  The electoral college is a group of electors t...   \n",
       "1376  fcfe84cb        1.0  An electoral College compromises between elect...   \n",
       "1377  fe6ff9a5        1.0  There has been a fuss about the Elector Colleg...   \n",
       "\n",
       "      generated                       prompt_name  \\\n",
       "0           0.0                   Car-free cities   \n",
       "1           0.0                   Car-free cities   \n",
       "2           0.0                   Car-free cities   \n",
       "3           0.0                   Car-free cities   \n",
       "4           0.0                   Car-free cities   \n",
       "...         ...                               ...   \n",
       "1373        0.0  Does the electoral college work?   \n",
       "1374        0.0  Does the electoral college work?   \n",
       "1375        0.0  Does the electoral college work?   \n",
       "1376        0.0  Does the electoral college work?   \n",
       "1377        0.0  Does the electoral college work?   \n",
       "\n",
       "                                           instructions  \\\n",
       "0     Write an explanatory essay to inform fellow ci...   \n",
       "1     Write an explanatory essay to inform fellow ci...   \n",
       "2     Write an explanatory essay to inform fellow ci...   \n",
       "3     Write an explanatory essay to inform fellow ci...   \n",
       "4     Write an explanatory essay to inform fellow ci...   \n",
       "...                                                 ...   \n",
       "1373  Write a letter to your state senator in which ...   \n",
       "1374  Write a letter to your state senator in which ...   \n",
       "1375  Write a letter to your state senator in which ...   \n",
       "1376  Write a letter to your state senator in which ...   \n",
       "1377  Write a letter to your state senator in which ...   \n",
       "\n",
       "                                            source_text  \n",
       "0     # In German Suburb, Life Goes On Without Cars ...  \n",
       "1     # In German Suburb, Life Goes On Without Cars ...  \n",
       "2     # In German Suburb, Life Goes On Without Cars ...  \n",
       "3     # In German Suburb, Life Goes On Without Cars ...  \n",
       "4     # In German Suburb, Life Goes On Without Cars ...  \n",
       "...                                                 ...  \n",
       "1373  # What Is the Electoral College? by the Office...  \n",
       "1374  # What Is the Electoral College? by the Office...  \n",
       "1375  # What Is the Electoral College? by the Office...  \n",
       "1376  # What Is the Electoral College? by the Office...  \n",
       "1377  # What Is the Electoral College? by the Office...  \n",
       "\n",
       "[1378 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "student_dataset =  dt.from_pandas(student_df[[\"text\", \"instructions\", \"source_text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\yuhei\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token = \"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('C')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/c%3A/Users/yuhei/.vscode/extensions/ms-ceintl.vscode-language-pack-ja-1.84.2023111509/translations/extensions/vscode.markdown-language-features.i18n.json'), WindowsPath('file')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/C'), WindowsPath('file'), WindowsPath('/Users/yuhei/anaconda3/envs/pytorch_env/etc/xml/catalog')}\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/matplotlib_inline.backend_inline'), WindowsPath('module')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=117, Highest Compute Capability: 8.6.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Required library version not found: libbitsandbytes_cuda117.so. Maybe you need to compile it from source?\n",
      "CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...\n",
      "\n",
      "================================================ERROR=====================================\n",
      "CUDA SETUP: CUDA detection failed! Possible reasons:\n",
      "1. You need to manually override the PyTorch CUDA version. Please see: \"https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "2. CUDA driver not installed\n",
      "3. CUDA not installed\n",
      "4. You have multiple conflicting CUDA libraries\n",
      "5. Required library not pre-compiled for this bitsandbytes release!\n",
      "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n",
      "CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.\n",
      "================================================================================\n",
      "\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n",
      "CUDA SETUP: Setup Failed!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yuhei\\VScode\\python\\LLM_Detect_AI_Generated_Text\\実験.ipynb セル 11\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maccelerate\u001b[39;00m \u001b[39mimport\u001b[39;00m infer_auto_device_map\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpeft\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     PeftModel,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     LoraConfig,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     get_peft_model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m peft_config \u001b[39m=\u001b[39m LoraConfig(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     r\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     lora_alpha\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     task_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSEQ_CLS\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m# テキスト分類の場合は\"SEQ_CLS\"となる\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X41sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m YOUR_TOKEN \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhf_NTIfezWgbxOCWhPMvuPsLggyzybsMfFYvN\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.6.3.dev0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     AutoPeftModel,\n\u001b[0;32m     24\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[0;32m     25\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[0;32m     26\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[0;32m     27\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[0;32m     28\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[0;32m     29\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[0;32m     33\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     inject_adapter_in_model,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     PeftModel,\n\u001b[0;32m     40\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     PeftModelForFeatureExtraction,\n\u001b[0;32m     46\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\auto.py:31\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     AutoModel,\n\u001b[0;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     AutoModelForTokenClassification,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     PeftModel,\n\u001b[0;32m     34\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     43\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_BaseAutoPeftModel\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\mapping.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     PeftModel,\n\u001b[0;32m     25\u001b[0m     PeftModelForCausalLM,\n\u001b[0;32m     26\u001b[0m     PeftModelForFeatureExtraction,\n\u001b[0;32m     27\u001b[0m     PeftModelForQuestionAnswering,\n\u001b[0;32m     28\u001b[0m     PeftModelForSeq2SeqLM,\n\u001b[0;32m     29\u001b[0m     PeftModelForSequenceClassification,\n\u001b[0;32m     30\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     AdaLoraConfig,\n\u001b[0;32m     34\u001b[0m     AdaLoraModel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     PromptTuningConfig,\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _prepare_prompt_learning_config\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\peft_model.py:39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     AdaLoraModel,\n\u001b[0;32m     41\u001b[0m     AdaptionPromptModel,\n\u001b[0;32m     42\u001b[0m     IA3Model,\n\u001b[0;32m     43\u001b[0m     LoHaModel,\n\u001b[0;32m     44\u001b[0m     LoKrModel,\n\u001b[0;32m     45\u001b[0m     LoraModel,\n\u001b[0;32m     46\u001b[0m     MultitaskPromptEmbedding,\n\u001b[0;32m     47\u001b[0m     PrefixEncoder,\n\u001b[0;32m     48\u001b[0m     PromptEmbedding,\n\u001b[0;32m     49\u001b[0m     PromptEncoder,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     52\u001b[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001b[0;32m     53\u001b[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     shift_tokens_right,\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     70\u001b[0m PEFT_TYPE_TO_MODEL_MAPPING \u001b[39m=\u001b[39m {\n\u001b[0;32m     71\u001b[0m     PeftType\u001b[39m.\u001b[39mLORA: LoraModel,\n\u001b[0;32m     72\u001b[0m     PeftType\u001b[39m.\u001b[39mLOHA: LoHaModel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     PeftType\u001b[39m.\u001b[39mIA3: IA3Model,\n\u001b[0;32m     80\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\tuners\\__init__.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madaption_prompt\u001b[39;00m \u001b[39mimport\u001b[39;00m AdaptionPromptConfig, AdaptionPromptModel\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlora\u001b[39;00m \u001b[39mimport\u001b[39;00m LoraConfig, LoraModel\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mloha\u001b[39;00m \u001b[39mimport\u001b[39;00m LoHaConfig, LoHaModel\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlokr\u001b[39;00m \u001b[39mimport\u001b[39;00m LoKrConfig, LoKrModel\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\tuners\\lora\\__init__.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgptq\u001b[39;00m \u001b[39mimport\u001b[39;00m QuantLinear\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlayer\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2d, Embedding, Linear, LoraLayer\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m LoraModel\n\u001b[0;32m     24\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mLoraConfig\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mConv2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mEmbedding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLoraLayer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLoraModel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mQuantLinear\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_available():\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\tuners\\lora\\model.py:45\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlayer\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2d, Embedding, Linear, LoraLayer\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_available():\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbnb\u001b[39;00m \u001b[39mimport\u001b[39;00m Linear8bitLt\n\u001b[0;32m     49\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_4bit_available():\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\bitsandbytes-0.41.2-py3.9.egg\\bitsandbytes\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     MatmulLtState,\n\u001b[0;32m      9\u001b[0m     bmm_cublas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     matmul_4bit\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\bitsandbytes-0.41.2-py3.9.egg\\bitsandbytes\\research\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     switchback_bnb,\n\u001b[0;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[0;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\bitsandbytes-0.41.2-py3.9.egg\\bitsandbytes\\research\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\bitsandbytes-0.41.2-py3.9.egg\\bitsandbytes\\research\\nn\\modules.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor, device, dtype, nn\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m GlobalOptimManager\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n\u001b[0;32m     11\u001b[0m T \u001b[39m=\u001b[39m TypeVar(\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, bound\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch.nn.Module\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\bitsandbytes-0.41.2-py3.9.egg\\bitsandbytes\\optim\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madagrad\u001b[39;00m \u001b[39mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madam\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam, Adam8bit, Adam32bit, PagedAdam, PagedAdam8bit, PagedAdam32bit\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\bitsandbytes-0.41.2-py3.9.egg\\bitsandbytes\\cextension.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mgenerate_instructions()\n\u001b[0;32m     19\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mprint_log_stack()\n\u001b[1;32m---> 20\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'''\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[39m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[39m    python -m bitsandbytes\u001b[39m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[39m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[39m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[39m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[39m'''\u001b[39m)\n\u001b[0;32m     28\u001b[0m lib\u001b[39m.\u001b[39mcadam32bit_grad_fp32 \u001b[39m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n\u001b[0;32m     29\u001b[0m lib\u001b[39m.\u001b[39mget_context\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39mc_void_p\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from accelerate import infer_auto_device_map\n",
    "from peft import (\n",
    "    PeftModel,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"query\", \"key\",  \"value\", \"out_proj\", \"dense\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",  # テキスト分類の場合は\"SEQ_CLS\"となる\n",
    ")\n",
    "\n",
    "YOUR_TOKEN = \"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\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained()\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bitsandbytes' has no attribute 'nn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yuhei\\VScode\\python\\LLM_Detect_AI_Generated_Text\\実験.ipynb セル 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpeft\u001b[39;00m \u001b[39mimport\u001b[39;00m LoraConfig, get_peft_model\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m lora_alpha \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yuhei/VScode/python/LLM_Detect_AI_Generated_Text/%E5%AE%9F%E9%A8%93.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m lora_dropout \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\__init__.py:22\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.6.3.dev0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     AutoPeftModel,\n\u001b[0;32m     24\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[0;32m     25\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[0;32m     26\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[0;32m     27\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[0;32m     28\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[0;32m     29\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     32\u001b[0m     MODEL_TYPE_TO_PEFT_MODEL_MAPPING,\n\u001b[0;32m     33\u001b[0m     PEFT_TYPE_TO_CONFIG_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     inject_adapter_in_model,\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m     PeftModel,\n\u001b[0;32m     40\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     PeftModelForFeatureExtraction,\n\u001b[0;32m     46\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\auto.py:31\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     AutoModel,\n\u001b[0;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     AutoModelForTokenClassification,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     PeftModel,\n\u001b[0;32m     34\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     43\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_BaseAutoPeftModel\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\mapping.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     24\u001b[0m     PeftModel,\n\u001b[0;32m     25\u001b[0m     PeftModelForCausalLM,\n\u001b[0;32m     26\u001b[0m     PeftModelForFeatureExtraction,\n\u001b[0;32m     27\u001b[0m     PeftModelForQuestionAnswering,\n\u001b[0;32m     28\u001b[0m     PeftModelForSeq2SeqLM,\n\u001b[0;32m     29\u001b[0m     PeftModelForSequenceClassification,\n\u001b[0;32m     30\u001b[0m     PeftModelForTokenClassification,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     AdaLoraConfig,\n\u001b[0;32m     34\u001b[0m     AdaLoraModel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m     PromptTuningConfig,\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _prepare_prompt_learning_config\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\peft_model.py:39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m     AdaLoraModel,\n\u001b[0;32m     41\u001b[0m     AdaptionPromptModel,\n\u001b[0;32m     42\u001b[0m     IA3Model,\n\u001b[0;32m     43\u001b[0m     LoHaModel,\n\u001b[0;32m     44\u001b[0m     LoKrModel,\n\u001b[0;32m     45\u001b[0m     LoraModel,\n\u001b[0;32m     46\u001b[0m     MultitaskPromptEmbedding,\n\u001b[0;32m     47\u001b[0m     PrefixEncoder,\n\u001b[0;32m     48\u001b[0m     PromptEmbedding,\n\u001b[0;32m     49\u001b[0m     PromptEncoder,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     52\u001b[0m     SAFETENSORS_WEIGHTS_NAME,\n\u001b[0;32m     53\u001b[0m     TRANSFORMERS_MODELS_TO_PREFIX_TUNING_POSTPROCESS_MAPPING,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     shift_tokens_right,\n\u001b[0;32m     67\u001b[0m )\n\u001b[0;32m     70\u001b[0m PEFT_TYPE_TO_MODEL_MAPPING \u001b[39m=\u001b[39m {\n\u001b[0;32m     71\u001b[0m     PeftType\u001b[39m.\u001b[39mLORA: LoraModel,\n\u001b[0;32m     72\u001b[0m     PeftType\u001b[39m.\u001b[39mLOHA: LoHaModel,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     PeftType\u001b[39m.\u001b[39mIA3: IA3Model,\n\u001b[0;32m     80\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\tuners\\__init__.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madaption_prompt\u001b[39;00m \u001b[39mimport\u001b[39;00m AdaptionPromptConfig, AdaptionPromptModel\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlora\u001b[39;00m \u001b[39mimport\u001b[39;00m LoraConfig, LoraModel\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mloha\u001b[39;00m \u001b[39mimport\u001b[39;00m LoHaConfig, LoHaModel\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlokr\u001b[39;00m \u001b[39mimport\u001b[39;00m LoKrConfig, LoKrModel\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\tuners\\lora\\__init__.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgptq\u001b[39;00m \u001b[39mimport\u001b[39;00m QuantLinear\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlayer\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2d, Embedding, Linear, LoraLayer\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m \u001b[39mimport\u001b[39;00m LoraModel\n\u001b[0;32m     24\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mLoraConfig\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mConv2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mEmbedding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLoraLayer\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLoraModel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mQuantLinear\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_available():\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\tuners\\lora\\model.py:47\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_available():\n\u001b[0;32m     45\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbnb\u001b[39;00m \u001b[39mimport\u001b[39;00m Linear8bitLt\n\u001b[0;32m     49\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_4bit_available():\n\u001b[0;32m     50\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbnb\u001b[39;00m \u001b[39mimport\u001b[39;00m Linear4bit\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\tuners\\lora\\bnb.py:182\u001b[0m\n\u001b[0;32m    178\u001b[0m             rep \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m()\n\u001b[0;32m    179\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mlora.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m rep\n\u001b[1;32m--> 182\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_4bit_available():\n\u001b[0;32m    184\u001b[0m     \u001b[39mclass\u001b[39;00m \u001b[39mLinear4bit\u001b[39;00m(torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule, LoraLayer):\n\u001b[0;32m    185\u001b[0m         \u001b[39m# Lora implemented in a dense layer\u001b[39;00m\n\u001b[0;32m    186\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    187\u001b[0m             \u001b[39mself\u001b[39m,\n\u001b[0;32m    188\u001b[0m             base_layer: torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    195\u001b[0m         ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yuhei\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\peft\\import_utils.py:32\u001b[0m, in \u001b[0;36mis_bnb_4bit_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mhasattr\u001b[39m(bnb\u001b[39m.\u001b[39;49mnn, \u001b[39m\"\u001b[39m\u001b[39mLinear4bit\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'bitsandbytes' has no attribute 'nn'"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
